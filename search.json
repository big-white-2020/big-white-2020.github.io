[{"title":"字符串","date":"2020-09-23T12:31:50.000Z","url":"/2020/09/23/redis-object1/","tags":[["Redis","/tags/Redis/"]],"categories":[[" ",""]],"content":" 字符串字符串的编码有 int、raw、embstr。 整数如果字符串对象保存的是一个整数时，Redis 可以用 long 类型来表示，在上节中 redisObject 的 encoding 置为 REDIS_ENCODING_INT，ptr 将保存整数值（void* 转换为 long）。例如下面这个例子 补充：可以用 long 、double 表示的浮点数在 redis 中也是用字符串值保存 在需要的时候再把字符串转换成浮点值。下表是 redis 保存各种数值类型的编码 数值类型 编码 可以用 long 表示的整数 int 可以用 long 、double 表示的浮点数 embstr、raw 长度太大，无法用 long、double 表示的整数或浮点数 embstr、raw raw 字符串如果字符串对象保存的是一个字符，且字符串长度大于 39 字节，redis 将采用 raw 编码。 embstr 字符串如果保存的字符小于等于 39 字节，redis 采用 embstr 编码保存字符串，embstr 底层实现也是 SDS 只是将 redisObject 与 sdshdr 分配在一块连续的空间，如下图： embstr 优点： raw 编码方式需要调用两次内存分配，分别为 redisObject 、sdshdr 分配空间，而 embstr 只需要调用一次内存分配即可 释放内存时也只需要一次 连续内存能更好的利用缓存 编码转换 int 编码转 raw 当对 int 编码的对象执行一些命令使其不是整数时，将转换成 raw 编码 embstr 编码转 raw redis 没有为 embstr 编码类型编写任何修改程序（只有对 int 和 raw 编码的修改程序），所以 embstr 实际上是只读字符串，任何对 embstr 编码字符串进行修改时，程序总会先转换成 raw 编码。 命令实现 命令 int 编码实现 embstr 编码实现 raw 编码实现 SET 使用 int 编码保存 使用 embstr 编码保存 使用 raw 编码保存 GET 先获取保存的整数，转换成字符串，返回客户端 直接向客户端返回字符串值 直接向客户端返回字符串值 APPEND 先将对象转换成 raw 编码，再按 raw 编码执行操作 先将对象转换成 raw 编码，再按 raw 编码执行操作 调用 sdscatlen 函数，将给定字符串追加到现有字符末尾 INCRBYFLOAT 取出整数值将其转换成 long double 类型的浮点的，再进行加法运算 取出字符串值，尝试转换成浮点数，再进行加法计算，如果不能转换，则返回错误 取出字符串值，尝试转换成浮点数，再进行加法计算，如果不能转换，则返回错误 INCRBY 进行加法计算 embstr 不能执行这个命令，返回错误 raw 不能执行这个命令，返回错误 DECRBY 进行减法计算 embstr 不能执行这个命令，返回错误 raw 不能执行这个命令，返回错误 STRLEN 先将对象转换成 raw 编码，再按 raw 编码执行操作 调用 sdslen 函数 调用 sdslen 函数 SETRANGE 先将对象转换成 raw 编码，再按 raw 编码执行操作 先将对象转换成 raw 编码，再按 raw 编码执行操作 将字符串特定索引上的值设置为给定的字符串 GETRANGE 将对象转换成字符串值，然后取出并返回字符串指定索引上的字符 直接取出并返回字符串指定索引上的字符 直接取出并返回字符串指定索引上的字符 "},{"title":"Redis 对象和编码","date":"2020-09-22T11:29:56.000Z","url":"/2020/09/22/redis-object/","tags":[["Redis","/tags/Redis/"]],"categories":[[" ",""]],"content":" 对象在 Redis 中用对象来表示键和值，每次创建一个键值对时至少创建两个对象，一个用于存放键对象，一个用于存放值对象。例如： 上面命令中，存储键是一个 msg 的字符串对象，存储值是一个 hello redis 的字符串对象。 Redis 的对象由一个 redisObject 结构体表示，结构代码如下： 类型上面代码中的 type 记录对象是什么类型（字符串、集合、哈希、列表、有序集合），type 的常量由下表所示： 常量 对象类型 TYPE 命令输出 REDIS_STRING 字符串 string REDIS_LIST 列表 list REDIS_HASH 哈希 hash REDIS_SET 集合 set REDIS_ZSET 有序集合 zset Redis 中的键总是字符串对象 可以使用 type &lt;key&gt; 命令查看值是什么对象 编码在 redisObject 中提到 ptr 是指向底层数据结构，因为每种对象底层有多种实现方式，所以 ptr 到底指向什么结构是由 encoding 决定的，encoding 记录了对象当前的编码（是什么数据结构实现）。encoding 常量由下表所示： 常量 数据结构 REDIS_ENCODING_INT long 类型整数 REDIS_ENCODING_EMBSTR embstr 编码的 SDS REDIS_ENCODING_RAW SDS REDIS_ENCODING_HT 字典 REDIS_ENCODING_LINKEDLIST 双端链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPLIST 跳跃表和字典 Redis 每个对象至少使用两种编码，如下表 类型 编码 对象实现方式 OBJECT ENCODING 命令输出 字符串 REDIS_STRING REDIS_ENCODING_INT 整数值 int REDIS_STRING REDIS_ENCODING_EMBSTR embstr 编码的简单动态字符串 embstr REDIS_STRING REDIS_ENCODING_RAW 简单动态字符串 raw 列表 REDIS_LIST REDIS_ENCODING_ZIPLIST 压缩列表 ziplist REDIS_LIST REDIS_ENCODING_LINKEDLIST 双端链表 linkedlist 哈希 REDIS_HASH REDIS_ENCODING_ZIPLIST 压缩列表 ziplist REDIS_HASH REDIS_ENCODING_HT 字典 hashtable 集合 REDIS_SET REDIS_ENCODING_INTSET 整数集合 intset REDIS_SET REDIS_ENCODING_HT 字典 hashtable 有序集合 REDIS_ZSET REDIS_ENCODING_ZIPLIST 压缩列表 ziplist REDIS_SET REDIS_ENCODING_SKIPLIST 跳跃表与字典 skiplist 可以使用 object encoding &lt;key&gt; 命令查看键对象的底层数据结构 使用 enconding 设定不同场景下不同的底层结构，有助于提升 redis 的灵活性和效率，例如，当一个列表元素较少时，底层使用压缩列表实现，压缩列表比双端链表更省空间，随着元素增多，使用压缩列表的优势慢慢消失，对象底层实现将转变成双端链表。 "},{"title":"JAVA 并发 —— 内存模型","date":"2020-09-20T07:36:09.000Z","url":"/2020/09/20/Java-memory-model/","tags":[["JAVA","/tags/JAVA/"],["并发","/tags/%E5%B9%B6%E5%8F%91/"]],"categories":[[" ",""]],"content":"并发编程模型的两个关键问题线程之间是如何通信和线程之间是如何同步。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 其中共享内存是指，线程之间通过读-写内存中的公共状态进行隐式通信。而消息传递并发模型中，线程之间没有公共状态，线程之间必须通过发送消息来显示进行通信。 同步是指程序中用于控制不同线程间操作发生相对顺序的机制，在共享内存并发模型中，同步是显示进行的，程序必须显示指定某个方法或者某段代码需要在线程之间互斥执行。而在消息传递并发模型中，由于消息的发送必须在消息的接收之前，所以是隐式进行的。 Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。 Java 内存模型的抽象结构Java 中的实例域、静态域和数组元素都存储在堆内存中，堆内存是线程共享的。而局部变量、方法定义参数和异常处理参数不会在线程间共享。 Java 线程之间的通信由 Java 内存模型（JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。如下图 JMM 抽象结构示意图。 上图中本地内存是一个抽象的概念，并不真实的存在，它包括缓存、写缓冲区、寄存器以及其它硬件和编译器优化。 如上图，如果线程A 要和 线程B 进行通信： 线程A 把本地内存A中更新过的共享变量刷新到主内存中。 线程B 到主内存中读取线程A之前更新过的共享变量 这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。 从源代码到指令序列的重排序在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。分为以下3种： 编译器优化的重排序。编译器不改变单线程程序语义前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是乱序执行。 从 Java 源代码到最终指向的指令序列，分别经历上面的三种重排序。 上述1 属于编译器重排序，2、3属于处理器重排序。这些重排序可能会导致多线程程序出现内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。 指令重排序和内存屏障 假设处理器A和处理器B按程序顺序并行执行内存访问，最终可能结果为 x=y=0。具体原因如下图所示： 从内存操作实际发生的顺序来看，直到处理器A执行A3来刷新自己的写缓存区，写操作A1才算真正执行了。虽然处理器A执行内存操作的顺序为：A1→A2，但内存操作实际发生的顺序却是A2→A1。此时，处理器A的内存操作顺序被重排序了（处理器B的情况和处理器A一样 ）。 为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为4类 ，如下图： StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。 happens-before 简介在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 happens-before 规则： 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读 注意：两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。happens-before的定义很微妙 。 重排序重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。 数据依赖性如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分为下列3种类型 编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序 (只针对单线程情况下，多线程处理器和编译器不考虑数据依赖性) as-if-serial 语义as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。 为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。 如下示例： 上面操作的数据依赖如下： 其中 C 依赖于 A，C 依赖于 B，所以 C 不能被排序到 A 和 B 之前，但是 A 与 B 之间是不存在数据依赖的，所以 A 和 B 的顺序是可以被重排序的。以下是重排序后的结果： 程序顺序规则根据 happens-before 的程序顺序规则，上面的例子存在3个 happens-before 关系 A happens-before B B happens-before C A happens-before C 第3个 happens-before 关系是根据 happens-before 传递性推导出来的。虽然 A happens-before B，但是 B 可能在 A 前面执行。如果A happens-before B，JMM并不要求A一定要在B之前执行。JMM仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里操作A的执行结果不需要对操作B可见；而且重排序操作A和操作B后的执行结果，与操作A和操作B按happens-before顺序执行的结果一致。在这种情况下，JMM会认为这种重排序并不非法（not illegal），JMM允许这种重排序。 重排序对多线程的影响 假设有两个线程A和B，A首先执行writer()方法，随后B线程接着执行reader()方法。线程B在执行操作4时，不一定能看到线程A在操作1对共享变量a的写入 。由于操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。 如果操作1 和操作 2 重拍序，如下图： 操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还没有被线程A写入，在这里多线程程序的语义被重排序破坏了。 当操作3和操作4重排序时会产生什么效果 ，如下图： 操作3和操作4存在__控制依赖__关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（Reorder Buffer，ROB）的硬件缓存中。当操作3的条件判断为真时，就把该计算结果写入变量i中。如上图，猜测执行实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义。 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。 顺序一致性顺序一致性内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照。 数据竞争与顺序一致性Java内存模型规范对数据竞争的定义如下：在一个线程中写一个变量，在另一个线程读同一个变量，而且写和读没有通过同步来排序。 代码中包含数据竞争时，程序执行结果往往与预测的结果不一致。如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。 JMM对正确同步的多线程程序的内存一致性做了如下保证。如果程序是正确同步的，程序的执行将具有顺序一致性（Sequentially Consistent）——即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。马上我们就会看到，这对于程序员来说是一个极强的保证。这里的同步是指广义上的同步，包括对常用同步原语（synchronized、volatile和final）的正确使用。 顺序一致性内存模型顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性。 一个线程中的所有操作必须按照程序的顺序来执行。 （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。 顺序一致性内存模型为程序员提供的视图如下图 在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程，同时每一个线程必须按照程序的顺序来执行内存读/写操作。从上面图可以看出，在任意时间点最多只能有一个线程可以连接到内存。 这样把所有线程的所有内存读/写操作串行化。 假设有两个线程A和B并发执行。其中A线程有3个操作，它们在程序中的顺序是：A1→A2→A3。B线程也有3个操作，它们在程序中的顺序是：B1→B2→B3。 假设这两个线程使用监视器锁来正确同步：A线程的3个操作执行后释放监视器锁，随后B线程获取同一个监视器锁。那么程序在顺序一致性模型中的执行效果将如下图示。 再假设这两个线程没有做同步，下面是这个未同步程序在顺序一致性模型中的执行示意图 未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。以上图为例，线程A和B看到的执行顺序都是：B1→A1→A2→B2→A3→B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。 在JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，当前线程写过的数据缓存在本地内存中，并没有刷新到主内存之前，这个写操作只对当前线程可见；从其他线程角度来看，这个写操作根本就没有执行。只有当前线程把本地内存写过的数据刷新到主内存中后，这个操作对其他线程才可见。这个时候，每个线程看到的执行顺序就不一致了。 同步程序的顺序一致性结果 假设A线程执行writer()方法后，B线程执行reader()方法。这是一个正确同步的多线程程序。根据JMM规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。 顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM中，临界区内的代码可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图。虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。 JMM在具体实现上的基本方针为：在不改变（正确同步的）程序执行结果的前提下，尽可能地为编译器和处理器的优化打开方便之门。 未同步程序的执行特性对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，Null，False），JMM保证线程读操作读取到的值不会无中生有（Out Of Thin Air）的冒出来。为了实现最小安全性，JVM在堆上分配对象时，首先会对内存空间进行清零，然后才会在上面分配对象（JVM内部会同步这两个操作）。因此，在已清零的内存空间（Pre-zeroed Memory）分配对象时，域的默认初始化已经完成了 。 JMM不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致。因为如果想要保证执行结果一致，JMM需要禁止大量的处理器和编译器的优化，这对程序的执行性能会产生很大的影响。而且，未同步程序在顺序一致性模型中，整体是无序的且结果无法预知，所以保证未同步程序在两个模型中执行结果一致也没什么意义。 未同步程序在两个模型中的执行特性有如下几个差异： 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序 JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。 在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（Bus Transaction）。总线事务包括读事务（Read Transaction）和写事务（Write Transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其他的处理器和I/O设备执行内存的读/写。 假设处理器A，B和C同时向总线发起总线事务，这时总线仲裁（Bus Arbitration）会对竞争做出裁决，这里假设总线在仲裁后判定处理器A在竞争中获胜（总线仲裁会确保所有处理器都能公平的访问内存）。此时处理器A继续它的总线事务，而其他两个处理器则要等待处理器A的总线事务完成后才能再次执行内存访问。假设在处理器A执行总线事务期间（不管这个总线事务是读事务还是写事务），处理器D向总线发起了总线事务，此时处理器D的请求会被总线禁止。 总线的这些工作机制可以把所有处理器对内存的访问以串行化的方式来执行。在任意时间点，最多只能有一个处理器可以访问内存。这个特性确保了单个总线事务之中的内存读/写操作具有原子性。 在一些32位的处理器上，如果要求对64位数据的写操作具有原子性，会有比较大的开销。为了照顾这种处理器，Java语言规范鼓励但不强求JVM对64位的long型变量和double型变量的写操作具有原子性。当JVM在这种处理器上运行时，可能会把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行。这两个32位的写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的写操作将不具有原子性。 当单个内存操作不具有原子性时，可能会产生意想不到后果。如下图 如上图，假如一个处理器A写一个Long整型变量，64位写操作被分成两个32位的写操作，且分配到不同事务上执行。同时处理器B的64位读操作被分配到同一个事务中执行。那么B只能读到A写了一半的无效值。 从 JDK5 开始只允许把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行，任意的读操作都必须具有原子性（即任意读操作必须要在单个读事务中执行）。"},{"title":"Java 并发 —— Volatile","date":"2020-09-20T07:15:45.000Z","url":"/2020/09/20/volatile/","tags":[["并发","/tags/%E5%B9%B6%E5%8F%91/"],["Java","/tags/Java/"],["volatile","/tags/volatile/"]],"categories":[[" ",""]],"content":"volatile 是轻量级的 synchronized，它在多处理器开发中保证共享变量的可见性，可见性是指当一个线程修改一个共享变量时，另一个线程能够读取到修改后的值。volatile 的执行成本比 sychronized 更低，因为 volatile 不会引起线程的上下文切换。 1.1 volatile 的定义与原理在连接 volatile 的原理之前，先看看实现原理相关的 CPU 术语 volatile 是怎么保证可见性的呢？通过获取 JIT 编译器生成的汇编指令来查看 Java 代码 instance = new Singleton(); // instance 是 volatile 变量 转换为汇编后 有 volatile 修饰的共享变量在进行写操作时会多出第二行汇编代码，第二行代码是一个 Lock 前缀的指令，在多核处理器下会引发： 将当前处理器缓存行的数据写会到系统内存。 这个写会内存操作会使其它处理器缓存了该内存地址的数据无效 为了提高处理速度，处理器会将系统内存的数据读到高速缓存中（L1、L2），但是对高速缓存操作后不知道什么时候写回到内存中，如果对用 volatile 修饰的变量进行写操作后，JVM 会向处理器发送一条 Lock 前缀的指令，这时就会将修改后的变量写回到内存中，但是，即使将变量写回后，在多处理器的情况下，其它处理器缓存的还是旧的值，所以就有了 缓存一致性协议 。每个处理器通过嗅探总线上传播的数据来检查自己的缓存值是不是过期了，如果发现自己缓存行对应的内存地址进行过修改，那就将自己的缓存行设置为无效，下次进行操作时，再到内存中读到缓存中。 volatile 的两条实现原则 Lock 前缀指令会引起处理器缓存写到内存 以前，在多处理器环境下，Lock# 信号在声言该信号期间，处理器会独占共享内存，对于 Intel486 和奔腾系列处理器，在锁操作时，总是在总线上声言 Lock# 信号。但是，在最近的处理器中 Lock# 信号一般不锁总线，而是锁定缓存。如果需要访问的内存区域已经缓存在处理器内部，则不会声言 Lock# 信号，它会锁定这块内存区域的缓存并写回到处理器内部，并使用缓存一致性机制来保证修改的原子性，称为 缓存锁定 ，缓存一致性会阻止同时修改两个及以上处理器缓存的内存区域数据。 一个处理器将缓存写回到内存导致其它处理器缓存的数据失效 IA-32处理器和Intel 64处理器使用MESI（修改、独占、共享、无效）控制协议去维护内部缓存和其他处理器缓存的一致性。在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统内存和它们的内部缓存。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。 volatile 的使用优化在 JDK7 的并发包中新增了一个队列集合类 LinkedTransferQueue，代码如下 它使用内部类来定义头节点（head）和尾节点（tail），这个内部类相对于父类只是将共享变量追加到 64 字节。一个对象引用占 4 个字节，追加 15 个变量（60 字节），再加上父类的 value 变量，一共是64 字节。因为现在主流的处理器的 L1、L2、L3的高速缓存行是64字节宽，不支持充分填充行，所以如果头结点和尾节点都不足64字节时，处理器会将他们读到一个缓存行中，多处理器下会缓存同样的头、尾节点，当一个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性协议下，其它的处理器不能访问自己缓存的尾节点，严重影响效率。 以下两种情况使用 volatile 变量时不应该追加到64字节 缓存行非64字节宽的处理器。 共享变量不会被频繁写，因为追加字节会导致处理器要读取更多的字节到高速缓存中，会消耗更多的性能。 volatile 的特性理解 volatile 特性的一个好方法就是把对 volatile 变量的单个读写看成是使用同一个锁对这些单个读/写操作做了同步。 如果多个线程分别调用上面程序的3个方法，这个程序的语义和下面的程序等价 可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性 volatile写-读建立的happens-before关系从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果：volatile写和锁的释放有相同的内存语义；volatile读与锁的获取有相同的内存语义。 假设线程A执行writer()方法之后，线程B执行reader()方法。根据happens-before规则，这个过程建立的happens-before关系可以分为3类： 根据程序次序规则，1 happens-before 2;3 happens-before 4 根据volatile规则，2 happens-before 3 根据happens-before的传递性规则，1 happens-before 4 volatile写-读的内存语义当写一个 volatile 变量时，JMM 会把该线程对应的本地内存中的共享变量值刷新到主内存。 当读一个volatile 变量时，JMM 会把该线程对应的本地内存置为无效，线程接下来将从主内存中读取共享变量。 volatile内存语义的实现下表是JMM针对编译器制定的volatile重排序规则表 当第一个操作为普通变量的读或写时，如果第二个操作为volatile写，则编译器不能重排序这两个操作，可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序 为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 下面是 volatile 写插入内存屏障后生成的指令序列示意图 StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。 这里比较有意思的是，volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确实现volatile的内存语义，JMM在采取了保守策略：__在每个volatile写的后面，或者在每个volatile读的前面插入一个StoreLoad屏障__。从整体执行效率的角度考虑，JMM最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。 下面是 volatile 读插入内存屏障后生成的指令序列示意图 在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。例如下面这个例子 针对readAndWrite()方法，编译器在生成字节码时可以做如下的优化 注意，最后的StoreLoad屏障不能省略。因为第二个volatile写之后，方法立即return。此时编译器可能无法准确断定后面是否会有volatile读或写，为了安全起见，编译器通常会在这里插入一个StoreLoad屏障。 "},{"title":"Git 基本使用","date":"2020-09-14T11:44:09.000Z","url":"/2020/09/14/Git/","tags":[["git","/tags/git/"],["tool","/tags/tool/"]],"categories":[[" ",""]],"content":"主要参考廖雪峰的官方网站-Git教程，删减上下文信息，把一些命令提取出来进行了简单的解释 基本操作 添加文件到仓库 查看工作区状态 版本回退 工作区和版本库 撤销修改 小结 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD &lt;file&gt;，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考[版本回退]，不过前提是没有推送到远程库。 删除文件 先手动删除文件，然后使用git rm 和git add效果是一样的 远程仓库 添加远程库 克隆远程仓库 分支管理 创建与合并分支 解决冲突 解决冲突 分支管理策略 上面讲到了合并分支的 Fast forward 方式，在这种模式下，删除分支后，会丢掉分支信息，如果强制禁用 Fast forward 模式，git 在 merge 时会生成一个新的 commit，就能保留分支信息 好的分支管理策略应该像下图一样： bug 分支 当 master 分支出现 bug 需要紧急修复时，需要创建新的 bug 分支进行修复，而自己的工作又只做到一半需要保存时，先把工作现场 修复 master 分支后发现当前工作的分支也有这个 bug，现在只需用 删除没有合并的分支 如果有一个实验性质没有合并的分支需要删除需要 多人协作 与远程分支建立联系 一般多人协作的模式如下： 首先，可以试图用git push origin 推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin 推送就能成功！ 如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch –set-upstream-to origin/。 Rebase 理想状态下希望提交记录是一条直线 可以通过 rebase 实现，一般把 rebase 叫变基，概念比较抽象，用下面几张图来解释a 初始情况： 使用 git rebase master 后，bugFix 分支上的工作在 master 的最顶端 然后切换到 master 分支，进行 git rebase bugFix 这里扩展一下 git pull 和 git pull –rebase 的区别 参考：简单对比git pull 和 git pull –rebase 的使用 同时还有一个经常使用的 git rebase -i ，这个命令可以选取你连续提交的多次进行合并。 标签管理"},{"title":"正则表达式-基础","date":"2020-09-14T11:44:09.000Z","url":"/2020/09/14/regular-expressions/","tags":[["regular","/tags/regular/"],["正则表达式","/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"]],"categories":[[" ",""]],"content":" 开头结尾^a 匹配的字符串以 a 开头（括号里除外） a$ 匹配字符串已 a 结尾 字符 [abc]，表示匹配中括号中的任意字符 [a-zA-Z0-9]，范围表示 [^a-z]，取反，表示不等于 a-z 中任意字符 .，表示任意字符（\\n 除外） \\s，表示空白字符，等同于 [\\r\\n\\t\\f\\v ] \\S，表示除了空白字符，即 [^\\r\\n\\t\\f\\v ] \\w，匹配字母数字下划线，等同于 [a-zA-Z0-9_] \\W，\\w 取反 \\d，匹配任意一个数字，即 [0-9] \\D，\\d 取反 上面几个转意匹配的，只要大小字母同时出现就可以匹配任意字符即 [\\s\\S] 就可以匹配任意字符。以上都是表示匹配单个字符，下面是匹配多个字符： a?，匹配 0 个或 1 个 a a*，匹配 0 个到无限个 a a+，匹配 1 个到无限个 a a&#123;m&#125;，匹配连续出现 m 次的 a a&#123;m,n&#125;，匹配连续出现 m - n 的 a a&#123;m,&#125;，匹配连续出现 m - 无穷的 a "},{"title":"JAVA8 新特性1 —— Lambda 表达式","date":"2020-09-14T09:15:45.000Z","url":"/2020/09/14/JAVA8-Lambda/","tags":[["JAVA","/tags/JAVA/"],["Lambda","/tags/Lambda/"],["JAVA8","/tags/JAVA8/"]],"categories":[[" ",""]],"content":"JAVA8的新特性核心是Lambda表达式和Steam API 一、Lambda表达式：1、语法：Java8中引入了一个新的操作符“-&gt;”，称为箭头操作符或Lambda操作符，箭头操作符将Lambda表达式拆分成两部分：左侧：Lambda表达式的参数列表右侧：Lambda表达式中所执行的功能，也称Lambda体 语法格式一：无参数，无返回值 语法格式二：有一个参数且无返回值 语法格式三：有两个及以上的参数，有返回值，并且Lambda体中有多条语句 语法格式四：如果Lambda体只有一条语句，大括号和 return 可以省略不写 注：Lambda 表达式的参数列表的数据类型可以不用写，JVM可以通过上下文可以自动推断数据类型。 2、Lambda 表达式需要“函数式接口”支持函数式接口：接口中只有一个抽象方法的接口，称为函数式接口。可以使用注解@FunctionalInterface 修饰检查是否为函数式接口用一个例子来说明： Lambda使用：①：声明一个函数式接口，接口中声明一个抽象方法。②：类中编写方法使用接口作为参数。③: 在调用②中方法时，接口参数部分使用 Lambda 表达式。 JAVA8 提供以下四大核心函数式接口 更多函数式接口可在java8官方文档中查看 Lambda 方法引用若Lambda体中的内容有方法已经实现了，可以用“方法引用”注意：lambda体中调用方法的参数列表与返回类型必须一致 1、类::静态方法名 2、对象::实例方法名 3、类::实例方法名若Lambda 参数列表的第一个参数是实例方法的调用者，第个参数是实例方法的参数是，可以使用ClassName::method 构造器引用ClassName :: new注意：需要调用的构造器的参数列表要与函数式接口中的抽象方法列表必须一致！ 数组引用格式：Type[]::new "},{"title":"JAVA NIO","date":"2020-09-13T11:44:09.000Z","url":"/2020/09/13/Java%20NIO/","tags":[["JAVA","/tags/JAVA/"],["NIO","/tags/NIO/"],["并发","/tags/%E5%B9%B6%E5%8F%91/"]],"categories":[[" ",""]],"content":"直接内存，间接内存&#8195;java.nio 从 Java 1.4开始引入，可以叫New I/O，也可叫Non-Blocking I/O。java.nio 有三个核心概念Selector、Channel、Buffer，在java.nio中我们是面向块（block）或者缓冲区（buffer）编程，而不是像 java.io 中的面向流编程。buffer 是内存中的一块区域，底层的实现是数组，所有数据的读或者写都是通过 buffer 来实现。 &#8195;对于Java的8中基本数据类型都有（除了 Boolean）对应的 Buffer 类型，如 ByteBuffer、CharBuffer、IntBuffer 等&#8195;Channel 是指可以写入或者读取数据的对象，类似于 java.io 中的 Stream，不过 Channel 是双向的，可以进行读写。但是所有的读写操作都是通过 Buffer 进行，不会直接通过 Channel 读写数据。 Buffer&#8195;Buffer 中有几个重要的属性 mark、position、limit、capacity，其中 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity。&#8195;capacity 表示缓冲区 Buffer 的容量，不能为负数。limit 为缓冲区的限制，不能为负，限制代表缓冲区中第一个不能读取或者写入元素的索引（下标）。&#8195;position 代表下一个要读取或者写入元素的索引（下标），不能为负。&#8195;mark 表示缓冲区的标记，标记的作用是调用 reset() 方法时，会将 position 位置重置到 mark 位置，标记不是必须的，而且标记不能大于 position，如果定义了 mark ，再将 position 或 limit 重置到比 mark 小的位置时会丢弃 mark，将 mark 置为 -1。如果未定义 mark 在调用 reset() 方法时会抛出 InvalidMarkException 异常。总结： 1 ）缓冲区的 capacity 不能为负数，缓冲区的 limit 不能为负数，缓冲区的 position 不能为负数 。2) position 不能大于其 limit 。3) limit 不能大于其 capacity 。4 ）如果定义了 mark ，则在将 position 或 limit 调整为小于该 mark 的值时，该 mark 被丢弃 。5 ）如果未定义 mark ，那么调用 reset（） 方法将导致抛出 InvalidMarkException 异常 。6 ）如果 position 大于新的 limit ，则 position 的值就是新 limit 的值 。7 ）当 limit 和 position 值一样时，在指定的 position 写入数据时会 出现异常，因为此位置是被限制的 。 flip() 方法例子： 上述例子中，将 niotest1.txt 读入 buffer 后进行了一次 flip 操作，下面是 flip 方法的源码。flip 操作将 limit 设置为当前的 position，下次读取操作时就不会超过赋值的界限，保证读取的数据都是有效的。然后 position 设置为 0，下次读取时能从下标 0 开始读，mark 设置为 -1 clear() 方法&#8195;clear 方法只是将 limit 设置为 capacity，position 设置为 0，并没有将数据删除，而只是将 buffer 数组设置为初始状态，下次写操作时直接覆盖，而读操作可以把原来的数据读出来。下面是 clear 方法的源码 相对位置和绝对位置ByteBuffer 类型化 put 和 get方法就是，将其他类型 put 进 ByteBuffer，但是，put 什么类型，get 就是什么类型，顺序不能变。 共享底层数组 slice 共享相同的数组直接缓冲和零拷贝 DirectBuffer 内存映射文件 MappedByteBuffer将文件的全部或者一部分映射到堆外内存中，Java即可以直接操作内存，而不用操作文件，减少I/O操作，提升操作效率 关于 Buffer 的 Scattering（分散）和 Gathering（收集）Scattering 是指在使用 Channel 进行读取的时候，如果我们传入的是一个 buffer 数组，那么会将第一个 buffer 读满后再读入第二个 buffer 依次进行。Gathering 是指写出的时候传入一个 buffer 数组，会将第一个 buffer 全部写出，再将第二个 buffer 全部写出，依次进行。 unicode 是编码方式utf 是存储方式utf-8 是unicode的实现方式"},{"title":"JAVA8 新特性2 —— Stream API","date":"2020-09-13T09:25:45.000Z","url":"/2020/09/13/JAVA8-Stream%20API/","tags":[["JAVA","/tags/JAVA/"],["JAVA8","/tags/JAVA8/"],["Stream API","/tags/Stream-API/"]],"categories":[[" ",""]],"content":"Steam API (java.util.stream.*) 三个步骤①：将数据源转换成流②：一系列中间操作③：产生一个新流（不改变源数据） 流（Stream）是什么？是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。**集合讲的是数据，流讲的是计算！** 注意：**①：Stream 自己不会存储元素。②：Stream 不会改变源对象。会返回一个处理后的新Stream。③：Stream 操作是延迟执行的。要等到需要结果的时候才执行** 一、创建 Stream 1、可以通过Collection 系列集合提供的 stream() (串形流) 或 parallelStream() (并行流)获取流 2、通过Arrays 中的静态方法 stream() 获取数组流 3、通过 Stream 类中的静态方法 of() 4、无限流 此时的流是没有任何效果的，只是被创建出来了，要通过中间操作或者终止操作才有效果 二、中间操作 中间操作，如果没有终止操作是不会有任何的执行 1、筛选与切片 filter：接收 Lambda，从流中排除某些元素 limit：截断流，使元素不超过给定数量。 skip(n)：跳过元素，返回一个扔掉前 n 个元素的流，若流中不足 n 个，返回空流，与 limit 互补 distinct：筛选，通过流所生成的 hashCode() 和 equals() 去除重复元素 终止操作：一次性执行全部内容，叫“惰性求值”或“延时加载“ 外部迭代 2、映射 map：接收 Lambda，将元素转换成其他形式或提取信息。接收一个函数作为参数，该函数会被应用每一个元素上，并将其映射成一个新的元素。 flatMap：接收一个函数作为参数，将流中的每个值都换成另一流，然后把所有流连接成一个流 map 案例 输出 flatMap 输出结果 map 和 flatMap 有点像 List 的 add 和 addAll 3、排序sorted：自然排序sorted(Comparator com)：订制排序 三、终止操作 1、查找与匹配allMatch：检查是否匹配所以元素anyMatch：检查是否至少匹配一个元素noneMatch：检查是否没有匹配所有元素findFirst：返回第一个元素findAny：返回当前流的任意元素count：返回流中元素的总个数max：返回流中最大值min：返回流中最小值 2、归约reduce(T identity, BinaryOperator)：将流中元素反复结合起来，得到一个值 3、收集collect：将流转换成其他形式，接收一个Collector接口实现，用于给Stream中元素做汇总的方法。 "},{"title":"ArrayList 源码解析","date":"2020-09-13T07:44:09.000Z","url":"/2020/09/13/ArrayList/","tags":[["JAVA","/tags/JAVA/"],["ArrayList","/tags/ArrayList/"],["集合","/tags/%E9%9B%86%E5%90%88/"],["源码","/tags/%E6%BA%90%E7%A0%81/"]],"categories":[[" ",""]],"content":"首先存储的数据结构为：transient Object[] elementData; 构造方法构造方法有三种： 无参构造方法：创建一个默认容量的空数组，但是这里用的是 目的是与 区分，知道第一次添加元素该扩容多少，挖坑，后续填 带初始容量的构造方法：在 new ArrayList 的时候指定一个整数参数，这个参数为初始容量大小，这里会做一个判断，分三种情况 参数正常，非负且大于0，创建一个大小为传入值的数组 参数为0，使用 EMPTY_ELEMENTDATA 异常 初始参数为集合，构造一个包含指定集合元素的列表，不过传入的列表的对象必须是 Collection&lt;? extends E&gt; 如果传入的集合没问题则创建一个元素为传入集合的List 如果传入的集合大小为0，则使用 EMPTY_ELEMENTDATA 添加元素添加元素的方法主要有四种 add(E e) 在添加元素之前要确保容量够，会根据一个原有 size + 1 生成的minCapacity 去进行比较，如果为空时，且是之前无参构造方法创建的对象（DEFAULTCAPACITY_EMPTY_ELEMENTDATA），会扩容到默认初始值为 10，如果是之前有参构造函数创建的方法，就判断 minCapacity 是否大于原来数组的长度，如果比原来数组长度小，即添加的元素要数组越界了，必须先扩容再添加。 首先扩容是原来容量的 1.5 倍，这里还有一个容量最大问题，如果容量超过了 MAX_ARRAY_SIZE，要么溢出，要么使用 Integer.MAX_VALUE，至于为什么 MAX_ARRAY_SIZE 为 nteger.MAX_VALUE - 8，官方说法是有些虚拟机在数组中保留了一些”header words”，需要给这些“header words”留一些空间。 中间还有一个 newCapacity - minCapacity &lt; 0 的判断，以我的理解应该是 oldCapacity 已经非常大了，再增长 1.5 倍就会溢出了，所以如果溢出了就增长 1 即可。 最后，添加元素 add(int index, E element) 指定位置插入 步骤与 1 基本一样，只是最后需要从 index开始都往后挪一个位置 再把插入的值放到 index 位置上。 addAll(Collection&lt;? extends E&gt; c) 增加一个集合 步骤与 1 也一样，只是确保容量的时候传的是原来 size + c.length，然后 addAll(int index, Collection&lt;? extends E&gt; c) 指定位置插入集合 步骤与 2 类似，只是将往后移动一个换成往后移动一段 删除元素 remove(int index) 先验证 index 是否合法，然后保存原来的值，最后 然后返回删除的值 remove(Object o) 这个方法是删除对象的，删除 List 中出现的第一个与参数相等的对象，且不返回删除值。这里如果传入 null 则用 == 进行比较，如果非空则用 equals 进行比较，找到相等的后，调用一个私有的不进行 index 检查，不返回值的 fastRemove方法 clear() 对数组每个元素置空，将 size 置0 removeAll(Collection&lt;?&gt; c) 采用覆盖的方式，对原数组进行遍历，判断 c 中是否包含，如果包含就直接覆盖 最后再对未被覆盖且不需要的元素置空，以便 GC retainAll(Collection&lt;?&gt; c) 这个方法与 removeAll 相反，是保留，实现方式与 removeAll 一样，只是 complement = true 查询数据 get(int index) 直接返回下标为 index 的元素 indexOf(Object o) 遍历数组，返回第一个等于 o 的元素的下标，否则返回 -1 lastIndexOf(Object o) 反向遍历数组，返回最后一个等于 o 的元素的下标，否则返回 -1 contains(Object o) 调用 indexOf()，判断返回值是否 &gt;=0 subList(int fromIndex, int toIndex) subList 返回一个子 List，但共用父 List，只是在每个操作时对下标添加一个 offset，特别是 add 操作，每次添加都要移动父 List 的元素，所以效率不高。 "},{"title":"Redis 基本数据结构","date":"2020-09-12T07:15:45.000Z","url":"/2020/09/12/redis-baseDataConstruct/","tags":[["Reids","/tags/Reids/"]],"categories":[[" ",""]],"content":"字符串Redis 没有使用 C 语言原生的字符串，而是重新定义了一种数据结构——SDS（Simple Dynamic String）简单动态字符串，数据结构如下 free : 表示 buf 中可用的字节空间 len : 表示字符串的长度（不包括结束符） buf : 字节数组，用于存放二进制字节 free 用于每次拼接前 SDS 较 C 语言原生字符串有何优势： 获取字符串长度时不用遍历整个数组，直接读取 len 长度即可，时间复杂度为 O(1)，C 语言中获取字符串长度需要遍历整个数组，时间复杂度为 O(n) 。 字符串拼接时不会出现内存溢出： C 字符串在做字符串拼接之前需要先手动进行内存重分配，再进行拼接，很容易遗忘这个步骤造成内存溢出；而 SDS 每次进行拼接前先判断 free 的长度是否够拼接的长度，如果不够，先进行扩容。 减少修改字符串时的内存重分配次数 C 字符串每次对字符串进行增长或缩短都需要对内存进行重分配。 SDS 采用空间预分配和惰性空间释放的方式 如果对 SDS 修改后，SDS 的空间未超过 1MB，则会分配和 len 属性同样大小的未使用空间，这时 len == free，例如：如果修改后 SDS 的大小为 20 字节，则会分配 20 字节的free 空间，此时 len == free == 20，buf == 20 + 20 + 1 (1 字节用于保存空字符) 如果 SDS 修改后大于等于 1MB ，则会分配 1MB 的 free 空间，例如：SDS 修改后为 20 MB，则会分配 1MB 的 free 空间，此时，len == 30MB，free == 1MB，buf == 30MB + 1MB + 1byte(1 字节用于保存空字符) 在对 SDS 进行缩短操作后，不会马上释放空间，而是保存在 buf 里，如果以后做增长操作就能用上。再内存不足或者其他真正需要释放时就会进行释放。 二进制安全 C 字符串的字符必须符合某种编码（例如 ASCLL），并且处理结尾其它位置都不能出现空字符。而 SDS 是二进制安全的，就是在保存和读出的时候不对内容做任何操作，如过滤、筛选等等，存入的是什么，读出来就是什么。 兼容 C 字符串的部分函数 SDS 遵循 C 字符串中的以空字符串结尾的方式，所以 SDS 可以重用 &lt;string.h&gt; 库的部分函数，如 strcasecmp(sds-&gt;buf, &quot;hello world&quot;)、strcat(c_string, sds-&gt;buf)等。 总结：SDS 与 C 字符的对比 C 字符串 SDS 获取字符串长度的复杂度为 O(N) 。 获取字符串长度的复杂度为 O(1) 。 API 是不安全的，可能会造成缓冲区溢出。 API 是安全的，不会造成缓冲区溢出。 修改字符串长度 N 次必然需要执行 N 次内存重分配。 修改字符串长度 N 次最多需要执行 N 次内存重分配。 只能保存文本数据。 可以保存文本或者二进制数据。 可以使用所有 &lt;string.h&gt; 库中的函数。 可以使用一部分 &lt;string.h&gt; 库中的函数。 链表Redis 的链表由 链表(list)和链表节点(listNode)组成。 Redis 链表的特点如下： 双端： 链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。 无环： 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。 带表头指针和表尾指针： 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。 带链表长度计数器： 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1) 。 多态： 链表节点使用 void* 指针来保存节点值， 并且可以通过 list 结构的 dup 、 free 、 match 三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。 字典 基本数据结构首先看下 Redis 中字典的哈希表： 其中： table 属性是一个数组，数组中的元素是指向 dictEntry 的指针，dictEntry 中保存一个键值对 上图是一个大小为 4 的空的哈希表。 然后我们看下哈希表节点： 其中： val 可以是一个指针，也可以是 uint64_t 或 int64_t 整数 next 是用来指向下一个节点的指针，用于解决冲突，没错，reids 哈希表用于解决冲突的方式就是链地址法 然后我们看下 Redis 字典的结构： 其中 ： type 和 privdata 属性是针对不同类型的键值对 ht 属性是大小为 2 的数组，一般只用 ht[0]，ht[1] 在 rehash 的时候才会使用 rehashidx 是在 rehash 时记录下标的，后面讲 rehash 的时候会用到 最后，看下 dictType 的实现： 上图是一个普通为进行 rehash 的字典 哈希算法我们将一个 &lt;k, v&gt; 对添加到字典里的步骤是： 计算 k 的 哈希值 根据哈希值，通过 sizemask 计算除索引值 根据索引放入哈希表数组中 Redis 计算哈希值和索引的方式： 注：Redis 使用 MurmurHash2 算法计算键的哈希值 解决哈希冲突Redis 的哈希表采用链地址法（separate chaining）来解决冲突 因为 dictEntry 组成的链表没有指向表尾的指针，所有为了考虑速度，总是将新节点添加到表头的位置 rehash在容量固定的情况下，性能会随着 &lt;K, V&gt; 断增多而下降，因为， &lt;K, V&gt; 越来越多，造成哈希冲突的情况越来越多，dictEntry 链表越来越长，导致每次取值都要对链表进行遍历，所以这种情况就需要扩容; 另一种情况就是，哈希表有一个很大的容量，而里面的 &lt;K, V&gt; 越来越少（一开始不断扩容，随着使用，不断删除里面的 &lt;K, V&gt; ），这时为了避免空间浪费就需要收缩。而扩容与收缩都是通过 rehash （重新散列）来实现。rehash 步骤如下： 为字典中的 ht[1] 分配空间，这里空间分配的大小取决于执行的操作 如果是扩容，ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n （ 2 的 n 次幂），假设 ht[0].used == 4，那么 4 * 2 = 8，2 的 3 次方刚好是 8，所以 ht[1] 大小就为 8 如果是收缩，ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n （ 2 的 n 次幂） 将 ht[0] 的 &lt;K, V&gt; rehash 到 ht[1] 上，rehash 就是重新计算哈希值和索引值 迁移完后，释放 ht[0] , 将 ht[1] 设置为 ht[0] 对上图进行扩容步骤 先分配空间：ht[0].used 当前的值为 4 ， 4 * 2 = 8 ， 而 8 （2^3）恰好是第一个大于等于 4 的 2 的 n 次方， 所以程序会将 ht[1] 哈希表的大小设置为 8 将 ht[0] 的 &lt;K, V&gt; rehash 到 ht[1] 上： 重置指针，释放空间： 什么时候进行扩容？以下两个条件满足其一就会进行扩容 服务器没有在执行 BGSAVE 命令或 BGREWRITEAOF 命令的时候，负载因子大于等于 1 时 服务器正在执行 BGSAVE 命令或 BGREWRITEAOF 命令的时候，负载因子大于等于 5 时 （BGSAVE 和 BGREWRITEAOF 命令是 Redis 的持久化相关的命令） 负载因子计算公式 渐进式 rehash上面说到了 rehash 的过程，将 4 个 &lt;K, V&gt; rehash 可以很快完成，但是如果 &lt;K, V&gt; 是百万级、千万级、亿级呢？如果一次将 ht[0 中所有 &lt;K, V&gt; rehash 到 ht[1]，那这个计算量会导致服务停止服务一段时间，直到 rehash 完成。 所以，rehash 并不是一次性完成的，而是分多次、渐进式的，渐进式 rehash 的步骤： 为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成 例如下面这个例子： 准备 rehash rehash 索引 0 上的 &lt;K, V&gt; rehash 索引 1 上的 &lt;K, V&gt; 依次 rehash 3、4 上的索引，在进行渐进式 rehash 的过程中，删除、查找、更新等操作都会在 ht[0] 和 ht[1] 两个哈希表上，但是每次添加都是添加到 ht[1] 中 跳表这篇跳表的文章写得很不错Skip List–跳表（全网最详细的跳表文章没有之一) 整数集合 数据结构 整数集合的所有元素都保存在 contents 数组中，这些元素按从小到大有序且不重复排列，虽然这里声明的 contents 是 int8_t 类型的，但是其真正类型取决于 encoding 如果 encoding 属性的值为 INTSET_ENC_INT16 ， 那么 contents 就是一个 int16_t 类型的数组， 数组里的每个项都是一个 int16_t 类型的整数值 （最小值为 -32,768 ，最大值为 32,767 ）。 如果 encoding 属性的值为 INTSET_ENC_INT32 ， 那么 contents 就是一个 int32_t 类型的数组， 数组里的每个项都是一个 int32_t 类型的整数值 （最小值为 -2,147,483,648 ，最大值为 2,147,483,647 ）。 如果 encoding 属性的值为 INTSET_ENC_INT64 ， 那么 contents 就是一个 int64_t 类型的数组， 数组里的每个项都是一个 int64_t 类型的整数值 （最小值为 -9,223,372,036,854,775,808 ，最大值为 9,223,372,036,854,775,807 ）。 如上图示例中 encoding 保存的是 INTSET_ENC_INT16 且数组长度为 5 的，所以 contents 占 16 * 5 = 80位，encoding 的编码取决于数组中最大的元素，也就是会出现这种情况，数组中只有一个元素是 INTSET_ENC_INT64 类型，其它都是 INTSET_ENC_INT16 类型，也要按照 INTSET_ENC_INT64 编码 升级当一个新元素要添加到数组里时，并且新元素比所有原来的元素都要长时，就要进行升级(upgrade)，升级共分三步： 根据新元素大小，扩展数组大小，并为新元素分配空间 将数组现有元素都转换成新元素类型，并放置到正确位置，且保证有序性 将新元素添加到数组中 比如上图的例子，每个元素都占 16 位，数组长度为 48 位 如果现在要添加一个 int32_t 类型的 65535 到集合里，此时就要进行升级，先要根据类型和元素个数计算分配的空间，(3 + 1) * 32 = 128 位 分配完空间后，对原有元素进行转换，因为元素 3 在 1、2、3、65535 中排第三，所以移动到索引 2 的位置上 最后升级完成后的结构 因为每次向集合添加新元素都有可能会引起升级，每次升级都要对元素进行转换，所以添加新元素的复杂度为 O(n)。 升级后新元素的位置 因为引发升级操作的新元素比现有所有元素都要大，所以这个新元素要么大于所有元素（索引为 length - 1），要么小于所有元素（索引为 0） 为什么要设计为升级 灵活 因为 C 语言是静态类型语言，般只使用 int16_t 类型的数组来保存 int16_t 类型的值， 只使用 int32_t 类型的数组来保存 int32_t 类型的值， 诸如此类。自动升级操作可以将 int16_t 、 int32_t 或者 int64_t 类型的整数添加到集合中，不用担心类型错误，非常灵活。 节约内存 如果要让一个数组同时能够保存 int16_t 、 int32_t 、int64_t 类型的元素，最简单的就是直接使用 int64_t 类型，有可能浪费内存。 降级 不会对升级后的数组进行降级 压缩列表压缩列表是为了节约内存而开发的 数据结构 "},{"title":"搜索","date":"2021-04-18T05:59:04.457Z","url":"/search/index.html","categories":[[" ",""]]},{"title":"标签云","date":"2021-04-18T05:59:04.457Z","url":"/tags/index.html","categories":[[" ",""]]}]